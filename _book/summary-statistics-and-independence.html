<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.4 Summary Statistics and Independence | DSCI 420: Mathematics for Machine Learning</title>
  <meta name="description" content="An expanded, interactive companion to Mathematics for Machine Learning by Deisenroth et al." />
  <meta name="generator" content="bookdown 0.45 and GitBook 2.6.7" />

  <meta property="og:title" content="6.4 Summary Statistics and Independence | DSCI 420: Mathematics for Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="An expanded, interactive companion to Mathematics for Machine Learning by Deisenroth et al." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.4 Summary Statistics and Independence | DSCI 420: Mathematics for Machine Learning" />
  
  <meta name="twitter:description" content="An expanded, interactive companion to Mathematics for Machine Learning by Deisenroth et al." />
  

<meta name="author" content="D420 Faculty Team" />


<meta name="date" content="2025-12-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sum-rule-product-rule-and-bayes-theorem.html"/>
<link rel="next" href="gaussian-distribution.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">D420: Mathematics for Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="table-of-symbols.html"><a href="table-of-symbols.html"><i class="fa fa-check"></i>Table of Symbols</a>
<ul>
<li class="chapter" data-level="" data-path="table-of-symbols.html"><a href="table-of-symbols.html#important-symbols-and-where-to-find-them"><i class="fa fa-check"></i>Important Symbols and Where to Find Them:</a></li>
<li class="chapter" data-level="" data-path="table-of-symbols.html"><a href="table-of-symbols.html#table-of-abbreviations-and-acronyms"><i class="fa fa-check"></i>Table of Abbreviations and Acronyms</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-and-motivation.html"><a href="introduction-and-motivation.html"><i class="fa fa-check"></i><b>1</b> Introduction and Motivation</a>
<ul>
<li class="chapter" data-level="1.1" data-path="finding-words-for-intuitions.html"><a href="finding-words-for-intuitions.html"><i class="fa fa-check"></i><b>1.1</b> Finding Words for Intuitions</a></li>
<li class="chapter" data-level="1.2" data-path="two-ways-to-read-this-book.html"><a href="two-ways-to-read-this-book.html"><i class="fa fa-check"></i><b>1.2</b> Two Ways to Read This Book</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="two-ways-to-read-this-book.html"><a href="two-ways-to-read-this-book.html#part-i-mathematical-foundations"><i class="fa fa-check"></i><b>1.2.1</b> Part I: Mathematical Foundations</a></li>
<li class="chapter" data-level="1.2.2" data-path="two-ways-to-read-this-book.html"><a href="two-ways-to-read-this-book.html#part-ii-machine-learning-applications"><i class="fa fa-check"></i><b>1.2.2</b> Part II: Machine Learning Applications</a></li>
<li class="chapter" data-level="1.2.3" data-path="two-ways-to-read-this-book.html"><a href="two-ways-to-read-this-book.html#learning-path"><i class="fa fa-check"></i><b>1.2.3</b> Learning Path</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="exercises-and-feedback.html"><a href="exercises-and-feedback.html"><i class="fa fa-check"></i><b>1.3</b> Exercises and Feedback</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>2</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="" data-path="vectors.html"><a href="vectors.html"><i class="fa fa-check"></i><strong>2.0</strong> Vectors</a>
<ul>
<li class="chapter" data-level="2.0.1" data-path="vectors.html"><a href="vectors.html#vector-spaces"><i class="fa fa-check"></i><b>2.0.1</b> Vector Spaces</a></li>
<li class="chapter" data-level="2.0.2" data-path="vectors.html"><a href="vectors.html#closure"><i class="fa fa-check"></i><b>2.0.2</b> Closure</a></li>
<li class="chapter" data-level="2.0.3" data-path="vectors.html"><a href="vectors.html#other-properties-of-vectors"><i class="fa fa-check"></i><b>2.0.3</b> Other Properties of Vectors</a></li>
<li class="chapter" data-level="2.0.4" data-path="vectors.html"><a href="vectors.html#geometric-interpretation-of-a-vector"><i class="fa fa-check"></i><b>2.0.4</b> Geometric Interpretation of a Vector</a></li>
</ul></li>
<li class="chapter" data-level="2.1" data-path="systems-of-linear-equations.html"><a href="systems-of-linear-equations.html"><i class="fa fa-check"></i><b>2.1</b> Systems of Linear Equations</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="systems-of-linear-equations.html"><a href="systems-of-linear-equations.html#solutions-to-systems-of-linear-equations"><i class="fa fa-check"></i><b>2.1.1</b> Solutions to Systems of Linear Equations</a></li>
<li class="chapter" data-level="2.1.2" data-path="systems-of-linear-equations.html"><a href="systems-of-linear-equations.html#geometric-interpretation"><i class="fa fa-check"></i><b>2.1.2</b> Geometric Interpretation</a></li>
<li class="chapter" data-level="2.1.3" data-path="systems-of-linear-equations.html"><a href="systems-of-linear-equations.html#matrix-formulation"><i class="fa fa-check"></i><b>2.1.3</b> Matrix Formulation</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="matrices.html"><a href="matrices.html"><i class="fa fa-check"></i><b>2.2</b> Matrices</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="matrices.html"><a href="matrices.html#matrix-addition"><i class="fa fa-check"></i><b>2.2.1</b> Matrix Addition</a></li>
<li class="chapter" data-level="2.2.2" data-path="matrices.html"><a href="matrices.html#matrix-multiplication"><i class="fa fa-check"></i><b>2.2.2</b> Matrix Multiplication</a></li>
<li class="chapter" data-level="2.2.3" data-path="matrices.html"><a href="matrices.html#identity-matrix"><i class="fa fa-check"></i><b>2.2.3</b> Identity Matrix</a></li>
<li class="chapter" data-level="2.2.4" data-path="matrices.html"><a href="matrices.html#matrix-properties"><i class="fa fa-check"></i><b>2.2.4</b> Matrix Properties</a></li>
<li class="chapter" data-level="2.2.5" data-path="matrices.html"><a href="matrices.html#matrix-inverse"><i class="fa fa-check"></i><b>2.2.5</b> Matrix Inverse</a></li>
<li class="chapter" data-level="2.2.6" data-path="matrices.html"><a href="matrices.html#matrix-transpose"><i class="fa fa-check"></i><b>2.2.6</b> Matrix Transpose</a></li>
<li class="chapter" data-level="2.2.7" data-path="matrices.html"><a href="matrices.html#symmetric-matrices"><i class="fa fa-check"></i><b>2.2.7</b> Symmetric Matrices</a></li>
<li class="chapter" data-level="2.2.8" data-path="matrices.html"><a href="matrices.html#scalar-multiplication"><i class="fa fa-check"></i><b>2.2.8</b> Scalar Multiplication</a></li>
<li class="chapter" data-level="2.2.9" data-path="matrices.html"><a href="matrices.html#compact-form-of-linear-systems"><i class="fa fa-check"></i><b>2.2.9</b> Compact Form of Linear Systems</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="solving-systems-of-equations.html"><a href="solving-systems-of-equations.html"><i class="fa fa-check"></i><b>2.3</b> Solving Systems of Equations</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="solving-systems-of-equations.html"><a href="solving-systems-of-equations.html#particular-and-general-solutions"><i class="fa fa-check"></i><b>2.3.1</b> Particular and General Solutions</a></li>
<li class="chapter" data-level="2.3.2" data-path="solving-systems-of-equations.html"><a href="solving-systems-of-equations.html#elementary-transformations"><i class="fa fa-check"></i><b>2.3.2</b> Elementary Transformations</a></li>
<li class="chapter" data-level="2.3.3" data-path="solving-systems-of-equations.html"><a href="solving-systems-of-equations.html#the-minus-1-trick"><i class="fa fa-check"></i><b>2.3.3</b> The Minus-1 Trick</a></li>
<li class="chapter" data-level="2.3.4" data-path="solving-systems-of-equations.html"><a href="solving-systems-of-equations.html#calculating-an-inverse-matrix-via-gaussian-elimination"><i class="fa fa-check"></i><b>2.3.4</b> Calculating an Inverse Matrix via Gaussian Elimination</a></li>
<li class="chapter" data-level="2.3.5" data-path="solving-systems-of-equations.html"><a href="solving-systems-of-equations.html#algorithms-for-solving-a-system-of-linear-equations"><i class="fa fa-check"></i><b>2.3.5</b> Algorithms for Solving a System of Linear Equations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="vector-spaces-1.html"><a href="vector-spaces-1.html"><i class="fa fa-check"></i><b>2.4</b> Vector Spaces</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="vector-spaces-1.html"><a href="vector-spaces-1.html#groups"><i class="fa fa-check"></i><b>2.4.1</b> Groups</a></li>
<li class="chapter" data-level="2.4.2" data-path="vector-spaces-1.html"><a href="vector-spaces-1.html#vector-subspaces"><i class="fa fa-check"></i><b>2.4.2</b> Vector Subspaces</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="linear-independence.html"><a href="linear-independence.html"><i class="fa fa-check"></i><b>2.5</b> Linear Independence</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="linear-independence.html"><a href="linear-independence.html#gaussian-elimination-method"><i class="fa fa-check"></i><b>2.5.1</b> Gaussian Elimination Method</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="basis-and-rank.html"><a href="basis-and-rank.html"><i class="fa fa-check"></i><b>2.6</b> Basis and Rank</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="basis-and-rank.html"><a href="basis-and-rank.html#generating-set-and-basis"><i class="fa fa-check"></i><b>2.6.1</b> Generating Set and Basis</a></li>
<li class="chapter" data-level="2.6.2" data-path="basis-and-rank.html"><a href="basis-and-rank.html#rank"><i class="fa fa-check"></i><b>2.6.2</b> Rank</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="linear-mappings.html"><a href="linear-mappings.html"><i class="fa fa-check"></i><b>2.7</b> Linear Mappings</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="linear-mappings.html"><a href="linear-mappings.html#matrix-representation-of-linear-mappings"><i class="fa fa-check"></i><b>2.7.1</b> Matrix Representation of Linear Mappings</a></li>
<li class="chapter" data-level="2.7.2" data-path="linear-mappings.html"><a href="linear-mappings.html#coordinate-systems-and-bases"><i class="fa fa-check"></i><b>2.7.2</b> Coordinate Systems and Bases</a></li>
<li class="chapter" data-level="2.7.3" data-path="linear-mappings.html"><a href="linear-mappings.html#basis-change-and-equivalence"><i class="fa fa-check"></i><b>2.7.3</b> Basis Change and Equivalence</a></li>
<li class="chapter" data-level="2.7.4" data-path="linear-mappings.html"><a href="linear-mappings.html#image-and-kernel-of-a-linear-mapping"><i class="fa fa-check"></i><b>2.7.4</b> Image and Kernel of a Linear Mapping</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="affine-spaces.html"><a href="affine-spaces.html"><i class="fa fa-check"></i><b>2.8</b> Affine Spaces</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="affine-spaces.html"><a href="affine-spaces.html#relation-to-linear-equations"><i class="fa fa-check"></i><b>2.8.1</b> Relation to Linear Equations</a></li>
<li class="chapter" data-level="2.8.2" data-path="affine-spaces.html"><a href="affine-spaces.html#affine-mappings"><i class="fa fa-check"></i><b>2.8.2</b> Affine Mappings</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analytic-geometry.html"><a href="analytic-geometry.html"><i class="fa fa-check"></i><b>3</b> Analytic Geometry</a>
<ul>
<li class="chapter" data-level="3.1" data-path="norms.html"><a href="norms.html"><i class="fa fa-check"></i><b>3.1</b> Norms</a></li>
<li class="chapter" data-level="3.2" data-path="inner-products.html"><a href="inner-products.html"><i class="fa fa-check"></i><b>3.2</b> Inner Products</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="inner-products.html"><a href="inner-products.html#symmetric-positive-definite-matrices"><i class="fa fa-check"></i><b>3.2.1</b> Symmetric, Positive Definite Matrices</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="lengths-and-distances.html"><a href="lengths-and-distances.html"><i class="fa fa-check"></i><b>3.3</b> Lengths and Distances</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="lengths-and-distances.html"><a href="lengths-and-distances.html#distance-and-metrics"><i class="fa fa-check"></i><b>3.3.1</b> Distance and Metrics</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="angles-and-orthogonality.html"><a href="angles-and-orthogonality.html"><i class="fa fa-check"></i><b>3.4</b> Angles and Orthogonality</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="angles-and-orthogonality.html"><a href="angles-and-orthogonality.html#orthogonal-matrices"><i class="fa fa-check"></i><b>3.4.1</b> Orthogonal Matrices</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="orthonormal-basis.html"><a href="orthonormal-basis.html"><i class="fa fa-check"></i><b>3.5</b> Orthonormal Basis</a></li>
<li class="chapter" data-level="3.6" data-path="orthogonal-complement.html"><a href="orthogonal-complement.html"><i class="fa fa-check"></i><b>3.6</b> Orthogonal Complement</a></li>
<li class="chapter" data-level="3.7" data-path="inner-product-of-functions.html"><a href="inner-product-of-functions.html"><i class="fa fa-check"></i><b>3.7</b> Inner Product of Functions</a></li>
<li class="chapter" data-level="3.8" data-path="orthogonal-projections.html"><a href="orthogonal-projections.html"><i class="fa fa-check"></i><b>3.8</b> Orthogonal Projections</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="orthogonal-projections.html"><a href="orthogonal-projections.html#projection-onto-a-line"><i class="fa fa-check"></i><b>3.8.1</b> Projection onto a Line</a></li>
<li class="chapter" data-level="3.8.2" data-path="orthogonal-projections.html"><a href="orthogonal-projections.html#projection-onto-general-subspaces"><i class="fa fa-check"></i><b>3.8.2</b> Projection onto General Subspaces</a></li>
<li class="chapter" data-level="3.8.3" data-path="orthogonal-projections.html"><a href="orthogonal-projections.html#gram-schmidt-orthogonalization"><i class="fa fa-check"></i><b>3.8.3</b> Gram-Schmidt Orthogonalization</a></li>
<li class="chapter" data-level="3.8.4" data-path="orthogonal-projections.html"><a href="orthogonal-projections.html#projection-onto-affine-subspaces"><i class="fa fa-check"></i><b>3.8.4</b> Projection onto Affine Subspaces</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="rotations.html"><a href="rotations.html"><i class="fa fa-check"></i><b>3.9</b> Rotations</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="rotations.html"><a href="rotations.html#rotations-in-mathbbr2"><i class="fa fa-check"></i><b>3.9.1</b> Rotations in <span class="math inline">\(\mathbb{R}^2\)</span></a></li>
<li class="chapter" data-level="3.9.2" data-path="rotations.html"><a href="rotations.html#rotations-in-mathbbr3"><i class="fa fa-check"></i><b>3.9.2</b> Rotations in <span class="math inline">\(\mathbb{R}^3\)</span></a></li>
<li class="chapter" data-level="3.9.3" data-path="rotations.html"><a href="rotations.html#rotations-in-n-dimensions"><i class="fa fa-check"></i><b>3.9.3</b> Rotations in <span class="math inline">\(n\)</span> Dimensions</a></li>
<li class="chapter" data-level="3.9.4" data-path="rotations.html"><a href="rotations.html#properties-of-rotations"><i class="fa fa-check"></i><b>3.9.4</b> Properties of Rotations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="matrix-decompositions.html"><a href="matrix-decompositions.html"><i class="fa fa-check"></i><b>4</b> Matrix Decompositions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="determinant-and-trace.html"><a href="determinant-and-trace.html"><i class="fa fa-check"></i><b>4.1</b> Determinant and Trace</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="determinant-and-trace.html"><a href="determinant-and-trace.html#geometric-interpretation-1"><i class="fa fa-check"></i><b>4.1.1</b> Geometric Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="determinant-and-trace.html"><a href="determinant-and-trace.html#properties-of-the-determinant"><i class="fa fa-check"></i><b>4.1.2</b> Properties of the Determinant</a></li>
<li class="chapter" data-level="4.1.3" data-path="determinant-and-trace.html"><a href="determinant-and-trace.html#trace"><i class="fa fa-check"></i><b>4.1.3</b> Trace</a></li>
<li class="chapter" data-level="4.1.4" data-path="determinant-and-trace.html"><a href="determinant-and-trace.html#characteristic-polynomial"><i class="fa fa-check"></i><b>4.1.4</b> Characteristic Polynomial</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="eigenvalues-and-eigenvectors.html"><a href="eigenvalues-and-eigenvectors.html"><i class="fa fa-check"></i><b>4.2</b> Eigenvalues and Eigenvectors</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="eigenvalues-and-eigenvectors.html"><a href="eigenvalues-and-eigenvectors.html#key-properties"><i class="fa fa-check"></i><b>4.2.1</b> Key Properties</a></li>
<li class="chapter" data-level="4.2.2" data-path="eigenvalues-and-eigenvectors.html"><a href="eigenvalues-and-eigenvectors.html#relations-to-determinant-and-trace"><i class="fa fa-check"></i><b>4.2.2</b> Relations to Determinant and Trace</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="cholesky-decomposition.html"><a href="cholesky-decomposition.html"><i class="fa fa-check"></i><b>4.3</b> Cholesky Decomposition</a></li>
<li class="chapter" data-level="4.4" data-path="eigendecomposition-and-diagonalization.html"><a href="eigendecomposition-and-diagonalization.html"><i class="fa fa-check"></i><b>4.4</b> Eigendecomposition and Diagonalization</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="eigendecomposition-and-diagonalization.html"><a href="eigendecomposition-and-diagonalization.html#diagonalizable-matrices"><i class="fa fa-check"></i><b>4.4.1</b> Diagonalizable Matrices</a></li>
<li class="chapter" data-level="4.4.2" data-path="eigendecomposition-and-diagonalization.html"><a href="eigendecomposition-and-diagonalization.html#eigendecomposition-theorems"><i class="fa fa-check"></i><b>4.4.2</b> Eigendecomposition Theorems</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="singular-value-decomposition-svd.html"><a href="singular-value-decomposition-svd.html"><i class="fa fa-check"></i><b>4.5</b> Singular Value Decomposition (SVD)</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="singular-value-decomposition-svd.html"><a href="singular-value-decomposition-svd.html#geometric-intuition"><i class="fa fa-check"></i><b>4.5.1</b> Geometric Intuition</a></li>
<li class="chapter" data-level="4.5.2" data-path="singular-value-decomposition-svd.html"><a href="singular-value-decomposition-svd.html#construction-of-the-svd"><i class="fa fa-check"></i><b>4.5.2</b> Construction of the SVD</a></li>
<li class="chapter" data-level="4.5.3" data-path="singular-value-decomposition-svd.html"><a href="singular-value-decomposition-svd.html#comparison-eigenvalue-decomposition-vs-svd"><i class="fa fa-check"></i><b>4.5.3</b> Comparison: Eigenvalue Decomposition vs SVD</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="matrix-approximation-via-svd.html"><a href="matrix-approximation-via-svd.html"><i class="fa fa-check"></i><b>4.6</b> Matrix Approximation via SVD</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="matrix-approximation-via-svd.html"><a href="matrix-approximation-via-svd.html#error-measurement"><i class="fa fa-check"></i><b>4.6.1</b> Error Measurement</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="matrix-phylogeny-overview.html"><a href="matrix-phylogeny-overview.html"><i class="fa fa-check"></i><b>4.7</b> Matrix Phylogeny (Overview)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="vector-calculus.html"><a href="vector-calculus.html"><i class="fa fa-check"></i><b>5</b> Vector Calculus</a>
<ul>
<li class="chapter" data-level="5.1" data-path="differentiation-of-univariate-functions.html"><a href="differentiation-of-univariate-functions.html"><i class="fa fa-check"></i><b>5.1</b> Differentiation of Univariate Functions</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="differentiation-of-univariate-functions.html"><a href="differentiation-of-univariate-functions.html#taylor-series-and-polynomial-approximation"><i class="fa fa-check"></i><b>5.1.1</b> Taylor Series and Polynomial Approximation</a></li>
<li class="chapter" data-level="5.1.2" data-path="differentiation-of-univariate-functions.html"><a href="differentiation-of-univariate-functions.html#differentiation-rules"><i class="fa fa-check"></i><b>5.1.2</b> Differentiation Rules</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="partial-differentiation-and-gradients.html"><a href="partial-differentiation-and-gradients.html"><i class="fa fa-check"></i><b>5.2</b> Partial Differentiation and Gradients</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="partial-differentiation-and-gradients.html"><a href="partial-differentiation-and-gradients.html#basic-rules-of-partial-differentiation"><i class="fa fa-check"></i><b>5.2.1</b> Basic Rules of Partial Differentiation</a></li>
<li class="chapter" data-level="5.2.2" data-path="partial-differentiation-and-gradients.html"><a href="partial-differentiation-and-gradients.html#multivariate-chain-rule-matrix-form"><i class="fa fa-check"></i><b>5.2.2</b> Multivariate Chain Rule (Matrix Form)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="gradients-of-vector-valued-functions.html"><a href="gradients-of-vector-valued-functions.html"><i class="fa fa-check"></i><b>5.3</b> Gradients of Vector-Valued Functions</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="gradients-of-vector-valued-functions.html"><a href="gradients-of-vector-valued-functions.html#dimensional-summary-of-derivatives"><i class="fa fa-check"></i><b>5.3.1</b> Dimensional Summary of Derivatives</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="gradients-of-matrices.html"><a href="gradients-of-matrices.html"><i class="fa fa-check"></i><b>5.4</b> Gradients of Matrices</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="gradients-of-matrices.html"><a href="gradients-of-matrices.html#gradients-as-tensors"><i class="fa fa-check"></i><b>5.4.1</b> Gradients as Tensors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="useful-identities-for-computing-gradients.html"><a href="useful-identities-for-computing-gradients.html"><i class="fa fa-check"></i><b>5.5</b> Useful Identities for Computing Gradients</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="probability-and-distributions.html"><a href="probability-and-distributions.html"><i class="fa fa-check"></i><b>6</b> Probability and Distributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="construction-of-a-probability-space.html"><a href="construction-of-a-probability-space.html"><i class="fa fa-check"></i><b>6.1</b> Construction of a Probability Space</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="construction-of-a-probability-space.html"><a href="construction-of-a-probability-space.html#philosophical-issues"><i class="fa fa-check"></i><b>6.1.1</b> Philosophical Issues</a></li>
<li class="chapter" data-level="6.1.2" data-path="construction-of-a-probability-space.html"><a href="construction-of-a-probability-space.html#bayesian-vs.-frequentist-interpretations"><i class="fa fa-check"></i><b>6.1.2</b> Bayesian vs. Frequentist Interpretations</a></li>
<li class="chapter" data-level="6.1.3" data-path="construction-of-a-probability-space.html"><a href="construction-of-a-probability-space.html#probability-and-random-variables"><i class="fa fa-check"></i><b>6.1.3</b> Probability and Random Variables</a></li>
<li class="chapter" data-level="6.1.4" data-path="construction-of-a-probability-space.html"><a href="construction-of-a-probability-space.html#statistics"><i class="fa fa-check"></i><b>6.1.4</b> Statistics</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="discrete-and-continuous-probabilities.html"><a href="discrete-and-continuous-probabilities.html"><i class="fa fa-check"></i><b>6.2</b> Discrete and Continuous Probabilities</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="discrete-and-continuous-probabilities.html"><a href="discrete-and-continuous-probabilities.html#discrete-probabilities"><i class="fa fa-check"></i><b>6.2.1</b> Discrete Probabilities</a></li>
<li class="chapter" data-level="6.2.2" data-path="discrete-and-continuous-probabilities.html"><a href="discrete-and-continuous-probabilities.html#continuous-probabilities"><i class="fa fa-check"></i><b>6.2.2</b> Continuous Probabilities</a></li>
<li class="chapter" data-level="6.2.3" data-path="discrete-and-continuous-probabilities.html"><a href="discrete-and-continuous-probabilities.html#contrasting-discrete-and-continuous-distributions"><i class="fa fa-check"></i><b>6.2.3</b> Contrasting Discrete and Continuous Distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="sum-rule-product-rule-and-bayes-theorem.html"><a href="sum-rule-product-rule-and-bayes-theorem.html"><i class="fa fa-check"></i><b>6.3</b> Sum Rule, Product Rule, and Bayes’ Theorem</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="sum-rule-product-rule-and-bayes-theorem.html"><a href="sum-rule-product-rule-and-bayes-theorem.html#the-sum-rule-marginalization-property"><i class="fa fa-check"></i><b>6.3.1</b> The Sum Rule (Marginalization Property)</a></li>
<li class="chapter" data-level="6.3.2" data-path="sum-rule-product-rule-and-bayes-theorem.html"><a href="sum-rule-product-rule-and-bayes-theorem.html#the-product-rule-factorization-property"><i class="fa fa-check"></i><b>6.3.2</b> The Product Rule (Factorization Property)</a></li>
<li class="chapter" data-level="6.3.3" data-path="sum-rule-product-rule-and-bayes-theorem.html"><a href="sum-rule-product-rule-and-bayes-theorem.html#bayes-theorem-probabilistic-inversion"><i class="fa fa-check"></i><b>6.3.3</b> Bayes’ Theorem (Probabilistic Inversion)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="summary-statistics-and-independence.html"><a href="summary-statistics-and-independence.html"><i class="fa fa-check"></i><b>6.4</b> Summary Statistics and Independence</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="summary-statistics-and-independence.html"><a href="summary-statistics-and-independence.html#means-and-covariances"><i class="fa fa-check"></i><b>6.4.1</b> Means and Covariances</a></li>
<li class="chapter" data-level="6.4.2" data-path="summary-statistics-and-independence.html"><a href="summary-statistics-and-independence.html#empirical-means-and-covariances"><i class="fa fa-check"></i><b>6.4.2</b> <strong>Empirical Means and Covariances</strong></a></li>
<li class="chapter" data-level="6.4.3" data-path="summary-statistics-and-independence.html"><a href="summary-statistics-and-independence.html#alternatice-expressions-for-the-variance"><i class="fa fa-check"></i><b>6.4.3</b> Alternatice Expressions for the Variance</a></li>
<li class="chapter" data-level="6.4.4" data-path="summary-statistics-and-independence.html"><a href="summary-statistics-and-independence.html#sums-and-transformations-of-random-variables"><i class="fa fa-check"></i><b>6.4.4</b> <strong>Sums and Transformations of Random Variables</strong></a></li>
<li class="chapter" data-level="6.4.5" data-path="summary-statistics-and-independence.html"><a href="summary-statistics-and-independence.html#statistical-independence"><i class="fa fa-check"></i><b>6.4.5</b> <strong>Statistical Independence</strong></a></li>
<li class="chapter" data-level="6.4.6" data-path="summary-statistics-and-independence.html"><a href="summary-statistics-and-independence.html#inner-products-and-geometry-of-random-variables"><i class="fa fa-check"></i><b>6.4.6</b> <strong>Inner Products and Geometry of Random Variables</strong></a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="gaussian-distribution.html"><a href="gaussian-distribution.html"><i class="fa fa-check"></i><b>6.5</b> Gaussian Distribution</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="gaussian-distribution.html"><a href="gaussian-distribution.html#joint-marginal-and-conditional-gaussians"><i class="fa fa-check"></i><b>6.5.1</b> Joint, Marginal, and Conditional Gaussians</a></li>
<li class="chapter" data-level="6.5.2" data-path="gaussian-distribution.html"><a href="gaussian-distribution.html#product-of-gaussian-densities"><i class="fa fa-check"></i><b>6.5.2</b> Product of Gaussian Densities</a></li>
<li class="chapter" data-level="6.5.3" data-path="gaussian-distribution.html"><a href="gaussian-distribution.html#mixtures-of-gaussians"><i class="fa fa-check"></i><b>6.5.3</b> Mixtures of Gaussians</a></li>
<li class="chapter" data-level="6.5.4" data-path="gaussian-distribution.html"><a href="gaussian-distribution.html#linear-and-affine-transformations-of-gaussians"><i class="fa fa-check"></i><b>6.5.4</b> Linear and Affine Transformations of Gaussians</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="continuous-optimization.html"><a href="continuous-optimization.html"><i class="fa fa-check"></i><b>7</b> Continuous Optimization</a>
<ul>
<li class="chapter" data-level="7.1" data-path="optimization-using-gradient-descent.html"><a href="optimization-using-gradient-descent.html"><i class="fa fa-check"></i><b>7.1</b> Optimization Using Gradient Descent</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="optimization-using-gradient-descent.html"><a href="optimization-using-gradient-descent.html#step-size-selection"><i class="fa fa-check"></i><b>7.1.1</b> Step-size Selection</a></li>
<li class="chapter" data-level="7.1.2" data-path="optimization-using-gradient-descent.html"><a href="optimization-using-gradient-descent.html#gradient-descent-with-momentum"><i class="fa fa-check"></i><b>7.1.2</b> Gradient Descent with Momentum</a></li>
<li class="chapter" data-level="7.1.3" data-path="optimization-using-gradient-descent.html"><a href="optimization-using-gradient-descent.html#stochastic-gradient-descent-sgd"><i class="fa fa-check"></i><b>7.1.3</b> Stochastic Gradient Descent (SGD)</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="constrained-optimization-and-lagrange-multipliers.html"><a href="constrained-optimization-and-lagrange-multipliers.html"><i class="fa fa-check"></i><b>7.2</b> Constrained Optimization and Lagrange Multipliers</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="constrained-optimization-and-lagrange-multipliers.html"><a href="constrained-optimization-and-lagrange-multipliers.html#from-constraints-to-the-lagrangian"><i class="fa fa-check"></i><b>7.2.1</b> From Constraints to the Lagrangian</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="convex-optimization.html"><a href="convex-optimization.html"><i class="fa fa-check"></i><b>7.3</b> Convex Optimization</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="convex-optimization.html"><a href="convex-optimization.html#convex-sets-and-functions"><i class="fa fa-check"></i><b>7.3.1</b> Convex Sets and Functions</a></li>
<li class="chapter" data-level="7.3.2" data-path="convex-optimization.html"><a href="convex-optimization.html#general-convex-optimization-problem"><i class="fa fa-check"></i><b>7.3.2</b> General Convex Optimization Problem</a></li>
<li class="chapter" data-level="7.3.3" data-path="convex-optimization.html"><a href="convex-optimization.html#quadratic-programming"><i class="fa fa-check"></i><b>7.3.3</b> Quadratic Programming</a></li>
<li class="chapter" data-level="7.3.4" data-path="convex-optimization.html"><a href="convex-optimization.html#legendrefenchel-transform-and-convex-conjugate"><i class="fa fa-check"></i><b>7.3.4</b> Legendre–Fenchel Transform and Convex Conjugate</a></li>
<li class="chapter" data-level="7.3.5" data-path="convex-optimization.html"><a href="convex-optimization.html#connection-to-duality"><i class="fa fa-check"></i><b>7.3.5</b> Connection to Duality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-models-and-learning.html"><a href="data-models-and-learning.html"><i class="fa fa-check"></i><b>8</b> Data, Models, and Learning</a>
<ul>
<li class="chapter" data-level="8.1" data-path="the-three-components-of-machine-learning.html"><a href="the-three-components-of-machine-learning.html"><i class="fa fa-check"></i><b>8.1</b> The Three Components of Machine Learning</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="the-three-components-of-machine-learning.html"><a href="the-three-components-of-machine-learning.html#data-as-vectors"><i class="fa fa-check"></i><b>8.1.1</b> Data as Vectors</a></li>
<li class="chapter" data-level="8.1.2" data-path="the-three-components-of-machine-learning.html"><a href="the-three-components-of-machine-learning.html#models-as-functions"><i class="fa fa-check"></i><b>8.1.2</b> Models as Functions</a></li>
<li class="chapter" data-level="8.1.3" data-path="the-three-components-of-machine-learning.html"><a href="the-three-components-of-machine-learning.html#models-as-probability-distributions"><i class="fa fa-check"></i><b>8.1.3</b> Models as Probability Distributions</a></li>
<li class="chapter" data-level="8.1.4" data-path="the-three-components-of-machine-learning.html"><a href="the-three-components-of-machine-learning.html#learning-as-finding-parameters"><i class="fa fa-check"></i><b>8.1.4</b> Learning as Finding Parameters</a></li>
<li class="chapter" data-level="8.1.5" data-path="the-three-components-of-machine-learning.html"><a href="the-three-components-of-machine-learning.html#regularization-and-model-complexity"><i class="fa fa-check"></i><b>8.1.5</b> Regularization and Model Complexity</a></li>
<li class="chapter" data-level="8.1.6" data-path="the-three-components-of-machine-learning.html"><a href="the-three-components-of-machine-learning.html#model-selection-and-hyperparameters"><i class="fa fa-check"></i><b>8.1.6</b> Model Selection and Hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="empirical-risk-minimization.html"><a href="empirical-risk-minimization.html"><i class="fa fa-check"></i><b>8.2</b> Empirical Risk Minimization</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="empirical-risk-minimization.html"><a href="empirical-risk-minimization.html#hypothesis-class-of-functions"><i class="fa fa-check"></i><b>8.2.1</b> Hypothesis Class of Functions</a></li>
<li class="chapter" data-level="8.2.2" data-path="empirical-risk-minimization.html"><a href="empirical-risk-minimization.html#loss-function-for-training"><i class="fa fa-check"></i><b>8.2.2</b> Loss Function for Training</a></li>
<li class="chapter" data-level="8.2.3" data-path="empirical-risk-minimization.html"><a href="empirical-risk-minimization.html#regularization-to-reduce-overfitting"><i class="fa fa-check"></i><b>8.2.3</b> Regularization to Reduce Overfitting</a></li>
<li class="chapter" data-level="8.2.4" data-path="empirical-risk-minimization.html"><a href="empirical-risk-minimization.html#cross-validation-to-assess-generalization"><i class="fa fa-check"></i><b>8.2.4</b> Cross-Validation to Assess Generalization</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>8.3</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="parameter-estimation.html"><a href="parameter-estimation.html#maximum-likelihood-estimation-mle"><i class="fa fa-check"></i><b>8.3.1</b> 8.3.1 Maximum Likelihood Estimation (MLE)</a></li>
<li class="chapter" data-level="8.3.2" data-path="parameter-estimation.html"><a href="parameter-estimation.html#maximum-a-posteriori-map-estimation"><i class="fa fa-check"></i><b>8.3.2</b> Maximum A Posteriori (MAP) Estimation</a></li>
<li class="chapter" data-level="8.3.3" data-path="parameter-estimation.html"><a href="parameter-estimation.html#model-fitting"><i class="fa fa-check"></i><b>8.3.3</b> Model Fitting</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="probabilistic-modeling-and-inference.html"><a href="probabilistic-modeling-and-inference.html"><i class="fa fa-check"></i><b>8.4</b> Probabilistic Modeling and Inference</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="probabilistic-modeling-and-inference.html"><a href="probabilistic-modeling-and-inference.html#probabilistic-models"><i class="fa fa-check"></i><b>8.4.1</b> Probabilistic Models</a></li>
<li class="chapter" data-level="8.4.2" data-path="probabilistic-modeling-and-inference.html"><a href="probabilistic-modeling-and-inference.html#bayesian-inference"><i class="fa fa-check"></i><b>8.4.2</b> Bayesian Inference</a></li>
<li class="chapter" data-level="8.4.3" data-path="probabilistic-modeling-and-inference.html"><a href="probabilistic-modeling-and-inference.html#latent-variable-models"><i class="fa fa-check"></i><b>8.4.3</b> Latent-Variable Models</a></li>
<li class="chapter" data-level="8.4.4" data-path="probabilistic-modeling-and-inference.html"><a href="probabilistic-modeling-and-inference.html#examples-of-latent-variable-models"><i class="fa fa-check"></i><b>8.4.4</b> Examples of Latent-Variable Models</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="directed-graphical-models.html"><a href="directed-graphical-models.html"><i class="fa fa-check"></i><b>8.5</b> Directed Graphical Models</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="directed-graphical-models.html"><a href="directed-graphical-models.html#graph-semantics"><i class="fa fa-check"></i><b>8.5.1</b> Graph Semantics</a></li>
<li class="chapter" data-level="8.5.2" data-path="directed-graphical-models.html"><a href="directed-graphical-models.html#conditional-independence-and-d-separation"><i class="fa fa-check"></i><b>8.5.2</b> Conditional Independence and d-Separation</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>8.6</b> Model Selection</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="model-selection.html"><a href="model-selection.html#nested-cross-validation"><i class="fa fa-check"></i><b>8.6.1</b> Nested Cross-Validation</a></li>
<li class="chapter" data-level="8.6.2" data-path="model-selection.html"><a href="model-selection.html#bayesian-model-selection"><i class="fa fa-check"></i><b>8.6.2</b> Bayesian Model Selection</a></li>
<li class="chapter" data-level="8.6.3" data-path="model-selection.html"><a href="model-selection.html#bayes-factors-for-model-comparison"><i class="fa fa-check"></i><b>8.6.3</b> Bayes Factors for Model Comparison</a></li>
<li class="chapter" data-level="8.6.4" data-path="model-selection.html"><a href="model-selection.html#computing-the-marginal-likelihood"><i class="fa fa-check"></i><b>8.6.4</b> Computing the Marginal Likelihood</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>9</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="problem-formulation.html"><a href="problem-formulation.html"><i class="fa fa-check"></i><b>9.1</b> Problem Formulation</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="problem-formulation.html"><a href="problem-formulation.html#parametric-models"><i class="fa fa-check"></i><b>9.1.1</b> Parametric Models</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="parameter-estimation-1.html"><a href="parameter-estimation-1.html"><i class="fa fa-check"></i><b>9.2</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="parameter-estimation-1.html"><a href="parameter-estimation-1.html#maximum-likelihood-estimation-mle-1"><i class="fa fa-check"></i><b>9.2.1</b> Maximum Likelihood Estimation (MLE)</a></li>
<li class="chapter" data-level="9.2.2" data-path="parameter-estimation-1.html"><a href="parameter-estimation-1.html#mle-with-nonlinear-features"><i class="fa fa-check"></i><b>9.2.2</b> MLE with Nonlinear Features</a></li>
<li class="chapter" data-level="9.2.3" data-path="parameter-estimation-1.html"><a href="parameter-estimation-1.html#overfitting-in-linear-regression"><i class="fa fa-check"></i><b>9.2.3</b> Overfitting in Linear Regression</a></li>
<li class="chapter" data-level="9.2.4" data-path="parameter-estimation-1.html"><a href="parameter-estimation-1.html#maximum-a-posteriori-map-estimation-1"><i class="fa fa-check"></i><b>9.2.4</b> Maximum A Posteriori (MAP) Estimation</a></li>
<li class="chapter" data-level="9.2.5" data-path="parameter-estimation-1.html"><a href="parameter-estimation-1.html#optimization"><i class="fa fa-check"></i><b>9.2.5</b> Optimization</a></li>
<li class="chapter" data-level="9.2.6" data-path="parameter-estimation-1.html"><a href="parameter-estimation-1.html#comparison-to-mle"><i class="fa fa-check"></i><b>9.2.6</b> Comparison to MLE</a></li>
<li class="chapter" data-level="9.2.7" data-path="parameter-estimation-1.html"><a href="parameter-estimation-1.html#map-estimation-as-regularization"><i class="fa fa-check"></i><b>9.2.7</b> MAP Estimation as Regularization</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="bayesian-linear-regression.html"><a href="bayesian-linear-regression.html"><i class="fa fa-check"></i><b>9.3</b> Bayesian Linear Regression</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="bayesian-linear-regression.html"><a href="bayesian-linear-regression.html#the-model"><i class="fa fa-check"></i><b>9.3.1</b> The Model</a></li>
<li class="chapter" data-level="9.3.2" data-path="bayesian-linear-regression.html"><a href="bayesian-linear-regression.html#posterior-distribution"><i class="fa fa-check"></i><b>9.3.2</b> Posterior Distribution</a></li>
<li class="chapter" data-level="9.3.3" data-path="bayesian-linear-regression.html"><a href="bayesian-linear-regression.html#posterior-predictions"><i class="fa fa-check"></i><b>9.3.3</b> Posterior Predictions</a></li>
<li class="chapter" data-level="9.3.4" data-path="bayesian-linear-regression.html"><a href="bayesian-linear-regression.html#marginal-likelihood"><i class="fa fa-check"></i><b>9.3.4</b> Marginal Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="maximum-likelihood-as-orthogonal-projection.html"><a href="maximum-likelihood-as-orthogonal-projection.html"><i class="fa fa-check"></i><b>9.4</b> Maximum Likelihood as Orthogonal Projection</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="maximum-likelihood-as-orthogonal-projection.html"><a href="maximum-likelihood-as-orthogonal-projection.html#simple-linear-regression-case"><i class="fa fa-check"></i><b>9.4.1</b> Simple Linear Regression Case</a></li>
<li class="chapter" data-level="9.4.2" data-path="maximum-likelihood-as-orthogonal-projection.html"><a href="maximum-likelihood-as-orthogonal-projection.html#general-linear-regression-case"><i class="fa fa-check"></i><b>9.4.2</b> General Linear Regression Case</a></li>
<li class="chapter" data-level="9.4.3" data-path="maximum-likelihood-as-orthogonal-projection.html"><a href="maximum-likelihood-as-orthogonal-projection.html#special-case-orthonormal-basis"><i class="fa fa-check"></i><b>9.4.3</b> Special Case: Orthonormal Basis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="dimensionality-reduction-with-principal-component-analysis-pca.html"><a href="dimensionality-reduction-with-principal-component-analysis-pca.html"><i class="fa fa-check"></i><b>10</b> Dimensionality Reduction with Principal Component Analysis (PCA)</a>
<ul>
<li class="chapter" data-level="10.1" data-path="principal-component-analysis-pca.html"><a href="principal-component-analysis-pca.html"><i class="fa fa-check"></i><b>10.1</b> Principal Component Analysis (PCA)</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="principal-component-analysis-pca.html"><a href="principal-component-analysis-pca.html#compression-interpretation"><i class="fa fa-check"></i><b>10.1.1</b> Compression Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="maximum-variance-perspective.html"><a href="maximum-variance-perspective.html"><i class="fa fa-check"></i><b>10.2</b> Maximum Variance Perspective</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="maximum-variance-perspective.html"><a href="maximum-variance-perspective.html#direction-with-maximal-variance"><i class="fa fa-check"></i><b>10.2.1</b> Direction with Maximal Variance</a></li>
<li class="chapter" data-level="10.2.2" data-path="maximum-variance-perspective.html"><a href="maximum-variance-perspective.html#m-dimensional-subspace-with-maximal-variance"><i class="fa fa-check"></i><b>10.2.2</b> M-Dimensional Subspace with Maximal Variance</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="projection-perspective.html"><a href="projection-perspective.html"><i class="fa fa-check"></i><b>10.3</b> Projection Perspective</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="projection-perspective.html"><a href="projection-perspective.html#setting-and-objective"><i class="fa fa-check"></i><b>10.3.1</b> Setting and Objective</a></li>
<li class="chapter" data-level="10.3.2" data-path="projection-perspective.html"><a href="projection-perspective.html#finding-optimal-coordinates"><i class="fa fa-check"></i><b>10.3.2</b> Finding Optimal Coordinates</a></li>
<li class="chapter" data-level="10.3.3" data-path="projection-perspective.html"><a href="projection-perspective.html#finding-the-basis-of-the-principal-subspace"><i class="fa fa-check"></i><b>10.3.3</b> Finding the Basis of the Principal Subspace</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="eigenvector-computation-and-low-rank-approximations.html"><a href="eigenvector-computation-and-low-rank-approximations.html"><i class="fa fa-check"></i><b>10.4</b> Eigenvector Computation and Low-Rank Approximations</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="eigenvector-computation-and-low-rank-approximations.html"><a href="eigenvector-computation-and-low-rank-approximations.html#computing-eigenvectors-via-covariance-and-svd"><i class="fa fa-check"></i><b>10.4.1</b> Computing Eigenvectors via Covariance and SVD</a></li>
<li class="chapter" data-level="10.4.2" data-path="eigenvector-computation-and-low-rank-approximations.html"><a href="eigenvector-computation-and-low-rank-approximations.html#pca-via-low-rank-matrix-approximations"><i class="fa fa-check"></i><b>10.4.2</b> PCA via Low-Rank Matrix Approximations</a></li>
<li class="chapter" data-level="10.4.3" data-path="eigenvector-computation-and-low-rank-approximations.html"><a href="eigenvector-computation-and-low-rank-approximations.html#practical-aspects-of-eigenvalue-computation"><i class="fa fa-check"></i><b>10.4.3</b> Practical Aspects of Eigenvalue Computation</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="pca-in-high-dimensions.html"><a href="pca-in-high-dimensions.html"><i class="fa fa-check"></i><b>10.5</b> PCA in High Dimensions</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="pca-in-high-dimensions.html"><a href="pca-in-high-dimensions.html#dimensionality-reduction-trick-for-n-ll-d"><i class="fa fa-check"></i><b>10.5.1</b> Dimensionality Reduction Trick for <span class="math inline">\(N \ll D\)</span></a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="key-steps-of-pca-in-practice.html"><a href="key-steps-of-pca-in-practice.html"><i class="fa fa-check"></i><b>10.6</b> Key Steps of PCA in Practice</a></li>
<li class="chapter" data-level="10.7" data-path="latent-variable-perspective.html"><a href="latent-variable-perspective.html"><i class="fa fa-check"></i><b>10.7</b> Latent Variable Perspective</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="latent-variable-perspective.html"><a href="latent-variable-perspective.html#probabilistic-pca-ppca"><i class="fa fa-check"></i><b>10.7.1</b> Probabilistic PCA (PPCA)</a></li>
<li class="chapter" data-level="10.7.2" data-path="latent-variable-perspective.html"><a href="latent-variable-perspective.html#likelihood-and-covariance-structure"><i class="fa fa-check"></i><b>10.7.2</b> Likelihood and Covariance Structure</a></li>
<li class="chapter" data-level="10.7.3" data-path="latent-variable-perspective.html"><a href="latent-variable-perspective.html#posterior-distribution-1"><i class="fa fa-check"></i><b>10.7.3</b> Posterior Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="density-estimation-with-gaussian-mixture-models.html"><a href="density-estimation-with-gaussian-mixture-models.html"><i class="fa fa-check"></i><b>11</b> Density Estimation with Gaussian Mixture Models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="gaussian-mixture-models-gmms.html"><a href="gaussian-mixture-models-gmms.html"><i class="fa fa-check"></i><b>11.1</b> Gaussian Mixture Models (GMMs)</a></li>
<li class="chapter" data-level="11.2" data-path="parameter-learning-via-maximum-likelihood.html"><a href="parameter-learning-via-maximum-likelihood.html"><i class="fa fa-check"></i><b>11.2</b> Parameter Learning via Maximum Likelihood</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="parameter-learning-via-maximum-likelihood.html"><a href="parameter-learning-via-maximum-likelihood.html#likelihood-and-log-likelihood"><i class="fa fa-check"></i><b>11.2.1</b> Likelihood and Log-Likelihood</a></li>
<li class="chapter" data-level="11.2.2" data-path="parameter-learning-via-maximum-likelihood.html"><a href="parameter-learning-via-maximum-likelihood.html#responsibilities"><i class="fa fa-check"></i><b>11.2.2</b> Responsibilities</a></li>
<li class="chapter" data-level="11.2.3" data-path="parameter-learning-via-maximum-likelihood.html"><a href="parameter-learning-via-maximum-likelihood.html#updating-parameters"><i class="fa fa-check"></i><b>11.2.3</b> Updating Parameters</a></li>
<li class="chapter" data-level="11.2.4" data-path="parameter-learning-via-maximum-likelihood.html"><a href="parameter-learning-via-maximum-likelihood.html#interpretation"><i class="fa fa-check"></i><b>11.2.4</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="expectation-maximization-em-algorithm.html"><a href="expectation-maximization-em-algorithm.html"><i class="fa fa-check"></i><b>11.3</b> Expectation-Maximization (EM) Algorithm</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="expectation-maximization-em-algorithm.html"><a href="expectation-maximization-em-algorithm.html#algorithm-steps"><i class="fa fa-check"></i><b>11.3.1</b> Algorithm Steps</a></li>
<li class="chapter" data-level="11.3.2" data-path="expectation-maximization-em-algorithm.html"><a href="expectation-maximization-em-algorithm.html#example-gmm-fit"><i class="fa fa-check"></i><b>11.3.2</b> Example: GMM Fit</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="latent-variable-perspective-1.html"><a href="latent-variable-perspective-1.html"><i class="fa fa-check"></i><b>11.4</b> Latent-Variable Perspective</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="latent-variable-perspective-1.html"><a href="latent-variable-perspective-1.html#generative-model"><i class="fa fa-check"></i><b>11.4.1</b> Generative Model</a></li>
<li class="chapter" data-level="11.4.2" data-path="latent-variable-perspective-1.html"><a href="latent-variable-perspective-1.html#likelihood"><i class="fa fa-check"></i><b>11.4.2</b> Likelihood</a></li>
<li class="chapter" data-level="11.4.3" data-path="latent-variable-perspective-1.html"><a href="latent-variable-perspective-1.html#posterior-distribution-2"><i class="fa fa-check"></i><b>11.4.3</b> Posterior Distribution</a></li>
<li class="chapter" data-level="11.4.4" data-path="latent-variable-perspective-1.html"><a href="latent-variable-perspective-1.html#extension-to-full-dataset"><i class="fa fa-check"></i><b>11.4.4</b> Extension to Full Dataset</a></li>
<li class="chapter" data-level="11.4.5" data-path="latent-variable-perspective-1.html"><a href="latent-variable-perspective-1.html#em-algorithm-revisited"><i class="fa fa-check"></i><b>11.4.5</b> EM Algorithm Revisited</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="classification-with-support-vector-machines-svms.html"><a href="classification-with-support-vector-machines-svms.html"><i class="fa fa-check"></i><b>12</b> Classification with Support Vector Machines (SVMs)</a>
<ul>
<li class="chapter" data-level="12.1" data-path="separating-hyperplanes.html"><a href="separating-hyperplanes.html"><i class="fa fa-check"></i><b>12.1</b> Separating Hyperplanes</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="separating-hyperplanes.html"><a href="separating-hyperplanes.html#classification-rule"><i class="fa fa-check"></i><b>12.1.1</b> Classification Rule</a></li>
<li class="chapter" data-level="12.1.2" data-path="separating-hyperplanes.html"><a href="separating-hyperplanes.html#training-objective"><i class="fa fa-check"></i><b>12.1.2</b> Training Objective</a></li>
<li class="chapter" data-level="12.1.3" data-path="separating-hyperplanes.html"><a href="separating-hyperplanes.html#geometric-interpretation-2"><i class="fa fa-check"></i><b>12.1.3</b> Geometric Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="primal-support-vector-machine.html"><a href="primal-support-vector-machine.html"><i class="fa fa-check"></i><b>12.2</b> Primal Support Vector Machine</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="primal-support-vector-machine.html"><a href="primal-support-vector-machine.html#traditional-derivation-of-the-margin"><i class="fa fa-check"></i><b>12.2.1</b> Traditional Derivation of the Margin</a></li>
<li class="chapter" data-level="12.2.2" data-path="primal-support-vector-machine.html"><a href="primal-support-vector-machine.html#why-we-can-set-the-margin-to-1"><i class="fa fa-check"></i><b>12.2.2</b> Why We Can Set the Margin to 1?</a></li>
<li class="chapter" data-level="12.2.3" data-path="primal-support-vector-machine.html"><a href="primal-support-vector-machine.html#soft-margin-svm-geometric-view"><i class="fa fa-check"></i><b>12.2.3</b> Soft Margin SVM: Geometric View</a></li>
<li class="chapter" data-level="12.2.4" data-path="primal-support-vector-machine.html"><a href="primal-support-vector-machine.html#soft-margin-svm-loss-function-view"><i class="fa fa-check"></i><b>12.2.4</b> Soft Margin SVM: Loss Function View</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="dual-support-vector-machine.html"><a href="dual-support-vector-machine.html"><i class="fa fa-check"></i><b>12.3</b> Dual Support Vector Machine</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="dual-support-vector-machine.html"><a href="dual-support-vector-machine.html#convex-duality-via-lagrange-multipliers"><i class="fa fa-check"></i><b>12.3.1</b> Convex Duality via Lagrange Multipliers</a></li>
<li class="chapter" data-level="12.3.2" data-path="dual-support-vector-machine.html"><a href="dual-support-vector-machine.html#dual-optimization-problem"><i class="fa fa-check"></i><b>12.3.2</b> Dual Optimization Problem</a></li>
<li class="chapter" data-level="12.3.3" data-path="dual-support-vector-machine.html"><a href="dual-support-vector-machine.html#dual-svm-convex-hull-view"><i class="fa fa-check"></i><b>12.3.3</b> Dual SVM: Convex Hull View</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="kernels.html"><a href="kernels.html"><i class="fa fa-check"></i><b>12.4</b> Kernels</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="kernels.html"><a href="kernels.html#feature-representations-and-kernels"><i class="fa fa-check"></i><b>12.4.1</b> Feature Representations and Kernels</a></li>
<li class="chapter" data-level="12.4.2" data-path="kernels.html"><a href="kernels.html#the-kernel-function-and-rkhs"><i class="fa fa-check"></i><b>12.4.2</b> The Kernel Function and RKHS</a></li>
<li class="chapter" data-level="12.4.3" data-path="kernels.html"><a href="kernels.html#common-kernels"><i class="fa fa-check"></i><b>12.4.3</b> Common Kernels</a></li>
<li class="chapter" data-level="12.4.4" data-path="kernels.html"><a href="kernels.html#practical-aspects"><i class="fa fa-check"></i><b>12.4.4</b> Practical Aspects</a></li>
<li class="chapter" data-level="12.4.5" data-path="kernels.html"><a href="kernels.html#terminology-note"><i class="fa fa-check"></i><b>12.4.5</b> Terminology Note</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DSCI 420: Mathematics for Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="summary-statistics-and-independence" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Summary Statistics and Independence<a href="summary-statistics-and-independence.html#summary-statistics-and-independence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This section explores how to summarize and compare random variables using summary statistics, covariance, and independence. These concepts are essential in understanding uncertainty, relationships between variables, and geometric interpretations in probability spaces.</p>
<hr />
<div id="means-and-covariances" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Means and Covariances<a href="summary-statistics-and-independence.html#means-and-covariances" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:unlabeled-div-47" class="definition"><strong>Definition 6.11  </strong></span>The <strong>expected value</strong> <span class="math inline">\(E_X[g(x)]\)</span> of a function <span class="math inline">\(g(x)\)</span> with respect to a random variable <span class="math inline">\(X\)</span> represents the long-run average outcome weighted by its probability.</p>
<ul>
<li><strong>Continuous case:</strong><br />
<span class="math display">\[
E_X[g(x)] = \int_X g(x)p(x)\,dx
\]</span><br />
</li>
<li><strong>Discrete case:</strong><br />
<span class="math display">\[
E_X[g(x)] = \sum_{x \in X} g(x)p(x)
\]</span></li>
</ul>
</div>
<p>The <strong>mean</strong> is a special case where <span class="math inline">\(g(x) = x\)</span>, giving <span class="math inline">\(E_X[x]\)</span>. Two other related measures of central tendency are:</p>
<ul>
<li><strong>Median:</strong> Middle value (robust to outliers)<br />
</li>
<li><strong>Mode:</strong> Most frequent or likely value</li>
</ul>
<div class="example">
<p><span id="exm:unlabeled-div-48" class="example"><strong>Example 6.17  </strong></span>Discrete Expected Value</p>
<p>Let <span class="math inline">\(X\)</span> be a discrete random variable representing the number shown when rolling a fair six-sided die. The probability Mass Function
<span class="math display">\[
P(X = x) = \frac{1}{6}, \quad x = 1,2,3,4,5,6
\]</span>
Thus, the expected Value is
<span class="math display">\[
\mathbb{E}[X] = \sum_{x=1}^6 x \, P(X=x)
= \frac{1}{6}(1+2+3+4+5+6)
= \frac{21}{6}
= 3.5
\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-49" class="example"><strong>Example 6.18  </strong></span>Continuous Expected Value with <span class="math inline">\(g(x) = x\)</span> (The Mean)</p>
<p>Let <span class="math inline">\(X \sim \text{Uniform}(0,2)\)</span>. The probability density function is
<span class="math display">\[
f(x) =
\begin{cases}
\frac{1}{2}, &amp; 0 \le x \le 2, \\
0, &amp; \text{otherwise}.
\end{cases}
\]</span>
Therefore, the expected Value is
<span class="math display">\[
\mathbb{E}[X] = \int_{-\infty}^{\infty} x f(x)\, dx
= \int_0^2 x \cdot \frac{1}{2} \, dx
\]</span>
<span class="math display">\[
= \frac{1}{2} \left[ \frac{x^2}{2} \right]_0^2
= \frac{1}{2} \cdot 2
= 1
\]</span>
This is the mean of the distribution.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-50" class="example"><strong>Example 6.19  </strong></span>Continuous Expected Value with <span class="math inline">\(g(x) \neq x\)</span></p>
<p>Let <span class="math inline">\(X \sim \text{Uniform}(0,1)\)</span>, and define:
<span class="math display">\[
g(X) = X^2
\]</span>
The expected Value of <span class="math inline">\(g(X)\)</span>
<span class="math display">\[
\mathbb{E}[g(X)] = \mathbb{E}[X^2]
= \int_0^1 x^2 \cdot 1 \, dx
\]</span>
<span class="math display">\[
= \left[ \frac{x^3}{3} \right]_0^1
= \frac{1}{3}.
\]</span></p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-51" class="definition"><strong>Definition 6.12  </strong></span><strong>Covariance</strong> measures how two random variables vary together:
<span class="math display">\[
  \text{Cov}[x, y] = E[xy] - E[x]E[y]
  \]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-52" class="example"><strong>Example 6.20  </strong></span>Covariance of Two Random Variables</p>
<p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be discrete random variables with the following joint probability distribution:</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th><span class="math inline">\(y\)</span></th>
<th><span class="math inline">\(p(x,y)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0</td>
<td><span class="math inline">\(0.25\)</span></td>
</tr>
<tr class="even">
<td>0</td>
<td>1</td>
<td><span class="math inline">\(0.25\)</span></td>
</tr>
<tr class="odd">
<td>1</td>
<td>0</td>
<td><span class="math inline">\(0.25\)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td><span class="math inline">\(0.25\)</span></td>
</tr>
</tbody>
</table>
<p>The expected value of <span class="math inline">\(X\)</span> is
<span class="math display">\[
E[X] = \sum_{x,y} x \, p(x,y)
= (0)(0.25) + (0)(0.25) + (1)(0.25) + (1)(0.25)
= 0.5.
\]</span></p>
<p>The expected value of <span class="math inline">\(Y\)</span> is
<span class="math display">\[
E[Y] = \sum_{x,y} y \, p(x,y)
= (0)(0.25) + (1)(0.25) + (0)(0.25) + (1)(0.25)
= 0.5.
\]</span></p>
<p>The expected value of <span class="math inline">\(XY\)</span> is
<span class="math display">\[
E[XY] = \sum_{x,y} xy \, p(x,y)
= (0)(0)(0.25) + (0)(1)(0.25) + (1)(0)(0.25) + (1)(1)(0.25)
= 0.25.
\]</span></p>
<p>Therefore, the covariance is
<span class="math display">\[
\text{Cov}[X,Y]
= E[XY] - E[X]E[Y]
= 0.25 - (0.5)(0.5)
= 0,
\]</span>
meaning there is no linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. In this case, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent random variables.</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-53" class="definition"><strong>Definition 6.13  </strong></span><strong>Variance</strong> is the covariance of a variable with itself:
<span class="math display">\[
  V[x] = \text{Cov}[x, x]
  \]</span></p>
</div>
<p>The variance describes how much the data spread around the mean.</p>
<div class="example">
<p><span id="exm:unlabeled-div-54" class="example"><strong>Example 6.21  </strong></span>Let <span class="math inline">\(X\)</span> be a discrete random variable with probability mass function:</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th><span class="math inline">\(p(x)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td><span class="math inline">\(0.2\)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td><span class="math inline">\(0.5\)</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math inline">\(0.3\)</span></td>
</tr>
</tbody>
</table>
<p>What is the variance of <span class="math inline">\(X\)</span>?</p>
<p>The expected value of <span class="math inline">\(X\)</span> is
<span class="math display">\[
E[X] = \sum_x x p(x)
= 0(0.2) + 1(0.5) + 2(0.3)
= 1.1
\]</span></p>
<p>The expected value of <span class="math inline">\(X^2\)</span> is
<span class="math display">\[
E[X^2] = \sum_x x^2 p(x)
= 0^2(0.2) + 1^2(0.5) + 2^2(0.3)
= 1.7
\]</span></p>
<p>Therefore, by definition,
<span class="math display">\[
\mathrm{Var}(X)
= \mathrm{Cov}(X, X)
= E[X^2] - E[X]^2
= 1.7 - (1.1)^2
= 1.7 - 1.21
= 0.49
\]</span></p>
<p>The variance measures how much the values of <span class="math inline">\(X\)</span> spread out around the mean. Here, the variance of <span class="math inline">\(X\)</span> is <span class="math inline">\(0.49\)</span>, which quantifies the variability of the random variable.</p>
</div>
<p>The <strong>covariance matrix</strong> summarizes all pairwise covariances for multivariate data and is symmetric and positive semi-definite. The covariance matrix has the following general form:</p>
<p><span class="math display">\[
\Sigma =
\begin{bmatrix}
\text{Cov}[x_1, x_1] &amp; \text{Cov}[x_1, x_2] &amp; \cdots &amp; \text{Cov}[x_1, x_D] \\
\text{Cov}[x_2, x_1] &amp; \text{Cov}[x_2, x_2] &amp; \cdots &amp; \text{Cov}[x_2, x_D] \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\text{Cov}[x_D, x_1] &amp; \text{Cov}[x_D, x_2] &amp; \cdots &amp; \text{Cov}[x_D, x_D]
\end{bmatrix}
\]</span></p>
<p><strong>Correlation</strong> normalizes covariance to the range <span class="math inline">\([-1, 1]\)</span>:
<span class="math display">\[
  \text{corr}[x, y] = \frac{\text{Cov}[x, y]}{\sqrt{V[x]V[y]}}
  \]</span></p>
<ul>
<li><span class="math inline">\(\text{corr} = 1\)</span>: perfect positive relationship<br />
</li>
<li><span class="math inline">\(\text{corr} = -1\)</span>: perfect negative relationship<br />
</li>
<li><span class="math inline">\(\text{corr} = 0\)</span>: uncorrelated variables</li>
</ul>
<hr />
</div>
<div id="empirical-means-and-covariances" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> <strong>Empirical Means and Covariances</strong><a href="summary-statistics-and-independence.html#empirical-means-and-covariances" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In practice, we estimate population statistics using sample data:</p>
<div class="definition">
<p><span id="def:unlabeled-div-55" class="definition"><strong>Definition 6.14  </strong></span><strong>Empirical Mean:</strong>
<span class="math display">\[
    \mathbf{a}r{x} = \frac{1}{N}\sum_{n=1}^{N} x_n
    \]</span>
<strong>Empirical Covariance:</strong>
<span class="math display">\[
    \Sigma = \frac{1}{N}\sum_{n=1}^{N}(x_n - \mathbf{a}r{x})(x_n - \mathbf{a}r{x})^\top
    \]</span></p>
</div>
<p>Both the empirical mean and covariance are the sample-based estimates of the true (population) parameters.</p>
<div class="example">
<p><span id="exm:unlabeled-div-56" class="example"><strong>Example 6.22  </strong></span>Suppose we observe paired data from two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. The data consist of <span class="math inline">\(n = 4\)</span> observations:</p>
<p><span class="math display">\[
(x_i, y_i) =
(1, 2),\;
(2, 3),\;
(3, 5),\;
(4, 4).
\]</span></p>
<p>The empirical mean (sample mean) of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is defined as
<span class="math display">\[
\mathbf{a}r{x} = \frac{1}{n}\sum_{i=1}^n x_i,
\qquad
\mathbf{a}r{y} = \frac{1}{n}\sum_{i=1}^n y_i.
\]</span></p>
<p>Compute each mean:
<span class="math display">\[
\mathbf{a}r{x} = \frac{1+2+3+4}{4} = 2.5,
\qquad
\mathbf{a}r{y} = \frac{2+3+5+4}{4} = 3.5.
\]</span></p>
<p>The empirical covariance between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is
<span class="math display">\[
\widehat{\mathrm{Cov}}(X,Y)
= \frac{1}{n}\sum_{i=1}^n (x_i - \mathbf{a}r{x})(y_i - \mathbf{a}r{y}).
\]</span></p>
<p>Compute each term:
<span class="math display">\[
\begin{aligned}
(1-2.5)(2-3.5) &amp;= ( -1.5)(-1.5) = 2.25, \\
(2-2.5)(3-3.5) &amp;= (-0.5)(-0.5) = 0.25, \\
(3-2.5)(5-3.5) &amp;= (0.5)(1.5) = 0.75, \\
(4-2.5)(4-3.5) &amp;= (1.5)(0.5) = 0.75.
\end{aligned}
\]</span></p>
<p>Sum and divide by <span class="math inline">\(n\)</span>:
<span class="math display">\[
\widehat{\mathrm{Cov}}(X,Y)
= \frac{2.25 + 0.25 + 0.75 + 0.75}{4}
= 1.0.
\]</span></p>
</div>
</div>
<div id="alternatice-expressions-for-the-variance" class="section level3 hasAnchor" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> Alternatice Expressions for the Variance<a href="summary-statistics-and-independence.html#alternatice-expressions-for-the-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are a number of alternative forms of the variance:</p>
<ul>
<li><strong>Definition:</strong><br />
<span class="math display">\[
  V[x] = E[(x - \mu)^2]
  \]</span><br />
</li>
<li><strong>Raw-score formula:</strong><br />
<span class="math display">\[
  V[x] = E[x^2] - (E[x])^2
  \]</span><br />
</li>
<li><strong>Pairwise difference form:</strong><br />
<span class="math display">\[
  \frac{1}{N^2}\sum_{i,j=1}^{N}(x_i - x_j)^2 = 2\left(E[x^2] - (E[x])^2\right)
  \]</span></li>
</ul>
<hr />
</div>
<div id="sums-and-transformations-of-random-variables" class="section level3 hasAnchor" number="6.4.4">
<h3><span class="header-section-number">6.4.4</span> <strong>Sums and Transformations of Random Variables</strong><a href="summary-statistics-and-independence.html#sums-and-transformations-of-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="lemma">
<p><span id="lem:unlabeled-div-57" class="lemma"><strong>Lemma 6.1  </strong></span>For two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>:
<span class="math display">\[
\begin{aligned}
E[x + y] &amp;= E[x] + E[y] \\
V[x + y] &amp;= V[x] + V[y] + 2\,\text{Cov}[x, y]
\end{aligned}
\]</span></p>
<p>If we apply an affine transformation <span class="math inline">\(y = A x + b\)</span>:
<span class="math display">\[
\begin{aligned}
E[y] &amp;= A E[x] + b, \\
V[y] &amp;= A V[x] A^\top
\end{aligned}
\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-58" class="example"><strong>Example 6.23  </strong></span><span class="math inline">\(V[x] = E[(x - \mu)^2]\)</span> is an equivalent version of <span class="math inline">\(V[x] = E[x^2] - (E[x])^2\)</span> (and this is exactly the definition of variance we gave earlier). If we recall that <span class="math inline">\(\mu = E[x]\)</span>, we can use the affine transformation property of the expected value to get:
<span class="math display">\[\begin{align*}
E[(x - \mu)^2] &amp;= E[(x - \mu)(x-\mu)] \\
&amp;= E[x^2 - 2\mu x + \mu^2] \\
&amp;= E[x^2] - 2\mu E[x] + \mu^2 \\
&amp;= E[x^2] - 2E[x]^2 + E[x]^2\\
&amp;=E[x^2] - E[x]^2.
\end{align*}\]</span></p>
</div>
<hr />
</div>
<div id="statistical-independence" class="section level3 hasAnchor" number="6.4.5">
<h3><span class="header-section-number">6.4.5</span> <strong>Statistical Independence</strong><a href="summary-statistics-and-independence.html#statistical-independence" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:unlabeled-div-59" class="definition"><strong>Definition 6.15  </strong></span><strong>Independent variables:</strong><br />
Two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent if<br />
<span class="math display">\[
  p(x, y) = p(x)p(y)
  \]</span>
<strong>Conditional independence:</strong><br />
<span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are conditionally independent given <span class="math inline">\(Z\)</span> if<br />
<span class="math display">\[
  p(x, y \mid z) = p(x \mid z)p(y \mid z)
  \]</span></p>
</div>
<p>Conditional independence is often written as <span class="math inline">\(X \perp\!\!\!\perp Y \mid Z\)</span>. These relationships are fundamental in probabilistic modeling and graphical models.</p>
<hr />
</div>
<div id="inner-products-and-geometry-of-random-variables" class="section level3 hasAnchor" number="6.4.6">
<h3><span class="header-section-number">6.4.6</span> <strong>Inner Products and Geometry of Random Variables</strong><a href="summary-statistics-and-independence.html#inner-products-and-geometry-of-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Random variables can be viewed as vectors in a space with inner products defined by covariance:
<span class="math display">\[
  \langle X, Y \rangle = \text{Cov}[x, y]
  \]</span>
The length of a random variable is its standard deviation:
<span class="math display">\[
  \|X\| = \sqrt{V[x]} = \sigma[x]
  \]</span>
The angle between random variables is related to correlation:
<span class="math display">\[
  \cos(\theta) = \frac{\text{Cov}[x, y]}{\sqrt{V[x]V[y]}} = \text{corr}[x, y]
  \]</span>
<span class="math inline">\(\theta = 90^\circ \Leftrightarrow\)</span> uncorrelated variables (orthogonal in this space)</p>
<p>This geometric interpretation helps visualize dependence and uncertainty.</p>
<hr />
</div>
<div id="exercises-33" class="section level3 unnumbered unlisted hasAnchor">
<h3>Exercises<a href="summary-statistics-and-independence.html#exercises-33" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="exercise">
<p><span id="exr:unlabeled-div-60" class="exercise"><strong>Exercise 6.17  </strong></span></p>
The distribution of the amount of gravel (in tons) sold by a particular construction supply company in a given week is a continuous RV <span class="math inline">\(X\)</span> with pdf <span class="math display">\[f(x) = \begin{cases} \dfrac{3}{2}(1-x^2) &amp; 0 \leq x \leq 1 \\ 0 &amp; otherwise \end{cases}.\]</span>
<div style="text-align: right;">
<p><a href="">Solution</a></p>
</div>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-61" class="exercise"><strong>Exercise 6.18  </strong></span></p>
Let <span class="math inline">\(X\)</span> be a random variable with PDF given by <span class="math display">\[f_X(x)= \begin{cases} cx^2 &amp; |x| \leq 1\\0 &amp; otherwise \end{cases}.\]</span>
<div style="text-align: right;">
<p><a href="">Solution</a></p>
</div>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-62" class="exercise"><strong>Exercise 6.19  </strong></span></p>
Let <span class="math inline">\(X\)</span> be a positive continuous random variable. Prove that <span class="math inline">\(E[X] = \int_{0}^{\infty} P(X \geq x) dx\)</span>.
<div style="text-align: right;">
<p><a href="">Solution</a></p>
</div>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-63" class="exercise"><strong>Exercise 6.20  </strong></span></p>
Show that <span class="math inline">\(cov[x,y] = E[xy] -E[x]E[y]\)</span>.
<div style="text-align: right;">
<p><a href="">Solution</a></p>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sum-rule-product-rule-and-bayes-theorem.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="gaussian-distribution.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["D420-Book.pdf", "D420-Book.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
